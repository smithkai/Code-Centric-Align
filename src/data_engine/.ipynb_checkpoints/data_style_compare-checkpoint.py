import json
import re
import numpy as np
import os

def get_code_stats(code):
    """æå–å•æ®µä»£ç çš„ç»Ÿè®¡ç‰¹å¾"""
    if not code or not isinstance(code, str):
        return None
    
    # ç§»é™¤ markdown æ ‡ç­¾
    code_clean = re.sub(r"```python\s*(.*?)\s*```", r"\1", code, flags=re.DOTALL).strip()
    if not code_clean:
        return None

    length = len(code_clean)
    lines = code_clean.split('\n')
    total_lines = len(lines) if len(lines) > 0 else 1
    # ç»Ÿè®¡æ³¨é‡Šè¡Œ (ä»¥#å¼€å¤´çš„è¡Œ)
    comment_lines = len([l for l in lines if l.strip().startswith('#')])
    
    return {
        "length": length,
        "lines": total_lines,
        "comment_ratio": comment_lines / total_lines
    }

def stream_analyze(file_path):
    """æµå¼åˆ†ææ–‡ä»¶ï¼Œæ”¯æŒ .json å’Œ .jsonl"""
    lengths = []
    lines_of_code = []
    comment_ratios = []
    
    print(f"ğŸ“– æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        # åˆ¤æ–­æ˜¯ json è¿˜æ˜¯ jsonl
        if file_path.endswith('.jsonl'):
            for line in f:
                if not line.strip(): continue
                item = json.loads(line)
                res = get_code_stats(item.get('output') or item.get('response') or "")
                if res:
                    lengths.append(res['length'])
                    lines_of_code.append(res['lines'])
                    comment_ratios.append(res['comment_ratio'])
        else:
            # å¯¹äºæ ‡å‡†çš„ .json åˆ—è¡¨ï¼Œä½¿ç”¨ ijson æˆ–ç®€å•çš„æµå¼åŠ è½½
            # è¿™é‡Œé’ˆå¯¹ä½ çš„ 199 æ¡å°æ–‡ä»¶ï¼Œç›´æ¥åŠ è½½å³å¯
            data = json.load(f)
            for item in data:
                res = get_code_stats(item.get('output') or item.get('response') or "")
                if res:
                    lengths.append(res['length'])
                    lines_of_code.append(res['lines'])
                    comment_ratios.append(res['comment_ratio'])

    if not lengths:
        return None

    return {
        "Avg Length": np.mean(lengths),
        "Avg Lines": np.mean(lines_of_code),
        "Comment %": np.mean(comment_ratios) * 100,
        "Max Length": np.max(lengths),
        "Sample Count": len(lengths)
    }

def main():
    # è·¯å¾„é…ç½® (è¯·æ ¹æ®å®é™…æƒ…å†µå¾®è°ƒ)
    model_file = "data/align/v3_deepseek_verified_dpo.json"
    gt_file = "data/raw/magicoder_raw.jsonl"

    if not os.path.exists(model_file) or not os.path.exists(gt_file):
        print("âŒ é”™è¯¯ï¼šè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        return

    # 1. åˆ†ææ¨¡å‹ç”Ÿæˆçš„ 199 æ¡æ•°æ®
    model_results = stream_analyze(model_file)
    
    # 2. åˆ†æåŸå§‹å·¨é‡æ•°æ®é›†
    gt_results = stream_analyze(gt_file)

    print("\n" + "="*60)
    print(f"{'æŒ‡æ ‡ (Metric)':<15} | {'æ¨¡å‹ç”Ÿæˆ (199æ¡)':<15} | {'åŸå§‹ GT æ•°æ®':<15}")
    print("-" * 60)
    
    for key in ["Avg Length", "Avg Lines", "Comment %", "Max Length", "Sample Count"]:
        m_val = model_results[key] if model_results else 0
        g_val = gt_results[key] if gt_results else 0
        print(f"{key:<15} | {m_val:<15.2f} | {g_val:<15.2f}")
    print("="*60)

if __name__ == "__main__":
    main()